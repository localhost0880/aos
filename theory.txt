Virtualization
Concept of Virtualization. 
● Virtualization is a technology that helps us to install different Operating 
Systems on a hardware. 
● They are completely separated and independent from each other. 
● Virtualization hides the physical characteristics of computing resources from 
their users, their applications or end users. This includes making a single 
physical resource 
(such as a server, an operating system, an application or a storage device) appear 
to function as multiple virtual resources. It can also include making multiple 
physical resources (such as storage devices or servers) appear as a single virtual 
resource...” 
Virtualization types: 
Server Virtualization: 
It is virtualizing your server infrastructure 
where you do not have to use any more 
physical servers for different purposes. 
Client and Desktop Virtualization: 
This is similar to server 
virtualization, but this time is on the 
user’s site where you virtualize their 
desktops. We change their desktops 
with thin clients and by utilizing the 
datacenter resources. 
Services and applications of 
Virtualization : The virtualization 
technology isolates applications from 
the underlying operating system and 
from other applications, in order to 
increase compatibility and 
manageability. For example – 
Docker can be used for that purpose. 
1. Network Virtualization 
It is a part of virtualization 
infrastructure, which is used 
especially if you are going to 
visualize your servers. It helps 
you in creating multiple 
switching, Vlans, NAT-ing, etc. 
The following illustration 
shows the VMware schema : 
2. Storage Virtualization 
This is widely used in data 
centers where you have a big 
storage and it helps you to 
create, delete, allocated storage 
to different hardware. This 
allocation is done through 
network connection. The leader 
on storage is SAN. A schematic 
illustration is given below: 
3. 
Hypervisor and its types. 
A hypervisor is a thin software layer that intercepts operating system calls to the hardware. 
It is also called the Virtual Machine Monitor (VMM). It creates a virtual 
platform on the host computer, on top of which multiple guest operating 
systems are executed and monitored. 
Hypervisors are two types: 
1. Native of Bare Metal Hypervisor 
Native hypervisors are software systems that run directly on the host's 
hardware to control the hardware and to monitor the Guest Operating 
Systems. The guest Operating system runs on a separate level above the 
hypervisor. All of them have Virtual Machine Manager. 
Examples of this virtual machine architecture are Oracle VM, Microsoft 
Hyper-V, VMWare ESX and Xen. 
2. Hosted Hypervisor 
Hosted hypervisors are designed to run within a traditional operating 
system. In other words, a hosted hypervisor adds a distinct software layer 
on top of the host operating system. While, the guest operating system 
becomes a third software level above the hardware. 
A well-known example of a hosted hypervisor is Oracle VM VirtualBox. 
Others include VMWare Server and Workstation, Microsoft Virtual PC, 
KVM, QEMU and Parallels. 
Advantages of Virtualization 
1. Using Virtualization for Efficient Hardware Utilization 
2. Using Virtualization to Increase Availability 
3. Disaster Recovery 
4. Save Energy 
5. Deploying Servers too fast 
6. Save Space in your Server Room or Datacenter 
7. Testing and setting up Lab Environment 
8. Shifting all your Local Infrastructure to Cloud in a day 
Disadvantages of Virtualization 
1. Extra Costs 
2. Software Licensing 
3. Learn the new Infrastructureirtualization**
Concept of Virtualization. 
● Virtualization is a technology that helps us to install different Operating 
Systems on a hardware. 
● They are completely separated and independent from each other. 
● Virtualization hides the physical characteristics of computing resources from 
their users, their applications or end users. This includes making a single 
physical resource 
(such as a server, an operating system, an application or a storage device) appear 
to function as multiple virtual resources. It can also include making multiple 
physical resources (such as storage devices or servers) appear as a single virtual 
resource...” 
Virtualization types: 
Server Virtualization: 
It is virtualizing your server infrastructure 
where you do not have to use any more 
physical servers for different purposes. 
Client and Desktop Virtualization: 
This is similar to server 
virtualization, but this time is on the 
user’s site where you virtualize their 
desktops. We change their desktops 
with thin clients and by utilizing the 
datacenter resources. 
Services and applications of 
Virtualization : The virtualization 
technology isolates applications from 
the underlying operating system and 
from other applications, in order to 
increase compatibility and 
manageability. For example – 
Docker can be used for that purpose. 
1. Network Virtualization 
It is a part of virtualization 
infrastructure, which is used 
especially if you are going to 
visualize your servers. It helps 
you in creating multiple 
switching, Vlans, NAT-ing, etc. 
The following illustration 
shows the VMware schema : 
2. Storage Virtualization 
This is widely used in data 
centers where you have a big 
storage and it helps you to 
create, delete, allocated storage 
to different hardware. This 
allocation is done through 
network connection. The leader 
on storage is SAN. A schematic 
illustration is given below: 
3. 
Hypervisor and its types. 
A hypervisor is a thin software layer that intercepts operating system calls to the hardware. 
It is also called the Virtual Machine Monitor (VMM). It creates a virtual 
platform on the host computer, on top of which multiple guest operating 
systems are executed and monitored. 
Hypervisors are two types: 
1. Native of Bare Metal Hypervisor 
Native hypervisors are software systems that run directly on the host's 
hardware to control the hardware and to monitor the Guest Operating 
Systems. The guest Operating system runs on a separate level above the 
hypervisor. All of them have Virtual Machine Manager. 
Examples of this virtual machine architecture are Oracle VM, Microsoft 
Hyper-V, VMWare ESX and Xen. 
2. Hosted Hypervisor 
Hosted hypervisors are designed to run within a traditional operating 
system. In other words, a hosted hypervisor adds a distinct software layer 
on top of the host operating system. While, the guest operating system 
becomes a third software level above the hardware. 
A well-known example of a hosted hypervisor is Oracle VM VirtualBox. 
Others include VMWare Server and Workstation, Microsoft Virtual PC, 
KVM, QEMU and Parallels. 
Advantages of Virtualization 
1. Using Virtualization for Efficient Hardware Utilization 
2. Using Virtualization to Increase Availability 
3. Disaster Recovery 
4. Save Energy 
5. Deploying Servers too fast 
6. Save Space in your Server Room or Datacenter 
7. Testing and setting up Lab Environment 
8. Shifting all your Local Infrastructure to Cloud in a day 
Disadvantages of Virtualization 
1. Extra Costs 
2. Software Licensing 
3. Learn the new Infrastructure

-------------------------------------------------------------------------------------------------------------------------------------------
Concept of Containerization and Dockers containers. 
containerization is a technology that allows you to package and run applications and their dependencies 
in isolated environments called containers. Containers are lightweight, portable, and can run consistently 
across different computing environments, from a developer's local machine to production servers. 
Key Concepts of Containerization: 
1. Isolation: Containers provide process and file system isolation, meaning that each container runs 
independently and does not interfere with others. This isolation ensures that the software inside 
the container runs the same way regardless of where it is deployed. 
2. Portability: Containers package the application code, runtime, libraries, and dependencies 
together, making it easy to move the application between different environments. This eliminates 
the "it works on my machine" problem and simplifies deployment. 
3. Efficiency: Containers share the host operating system's kernel, which allows them to be more 
resource-efficient compared to traditional virtual machines (VMs). They start up quickly and 
have a smaller footprint, which helps in optimizing resource utilization. 
4. Consistency: By using containers, developers can ensure that applications run consistently 
across different stages of development, testing, and production. This consistency reduces bugs 
and discrepancies related to environment differences. 
Docker Containers: 
Docker is one of the most popular platforms for containerization. It provides tools to create, manage, 
and deploy containers efficiently. Here are some key components and features of Docker: 
1. Docker Engine: This is the core component of Docker. It is a runtime that runs and manages 
containers on a host system. It includes the Docker daemon, which manages container 
operations, and the Docker CLI (Command Line Interface), which provides commands to 
interact with Docker. 
2. Docker Images: Docker images are read-only templates that contain the application code, 
libraries, dependencies, and runtime needed to run a container. Images are used to create 
containers. They are built from a Dockerfile, which is a script that defines the steps to assemble 
the image. 
3. Docker Containers: A container is an instance of a Docker image. It is a lightweight, 
standalone, and executable package that includes everything needed to run a piece of software. 
Containers are created from images and can be started, stopped, and managed through Docker. 
4. Docker Hub: Docker Hub is a cloud-based registry service where you can find, share, and store 
Docker images. It hosts public and private repositories of images and facilitates easy distribution 
and access. 
5. Docker Compose: Docker Compose is a tool that allows you to define and run multi-container 
Docker applications. Using a docker-compose.yml file, you can specify the services, networks, 
and volumes needed for your application, and Docker Compose manages the setup and 
orchestration of these components. 
6. Docker Swarm and Kubernetes: These are orchestration tools that manage the deployment, 
scaling, and operation of containers in a clustered environment. Docker Swarm is Docker's native 
clustering and orchestration tool, while Kubernetes is a more powerful and widely adopted 
orchestration system. 
In summary, containerization with Docker provides a powerful way to develop, deploy, and manage 
applications with high portability, consistency, and efficiency. Docker simplifies many aspects of 
container management and has become a standard tool in modern software development and operations. 

------------------------------------------------------------------------------------------------------------------------------------------

Introduction to Zones 
Definition: A zone is a lightweight virtualization method that provides isolated environments 
within a single operating system instance. Zones allow multiple independent user spaces, called 
containers or zones, to run on the same physical server, sharing the same OS kernel. 
Purpose: Zones are used to separate applications or services for security, resource management, 
and efficiency. Each zone operates like a distinct system, with its own processes, files, network 
settings, and users, despite sharing the underlying operating system kernel with other zones. 
Comparison Between Zones and Virtual Machines (VMs) 
 Kernel Sharing: 
o Zones: All zones share the same kernel with the global zone (the main or host 
environment), leading to less overhead and more efficient resource usage. 
o VMs: Each VM runs its own instance of an operating system with a separate kernel, 
which requires more resources and results in more overhead. 
 Resource Allocation: 
o Zones: More efficient in resource allocation as they don't need to replicate the entire OS. 
They are better suited for scenarios where multiple isolated environments need to coexist 
with minimal resource duplication. 
o VMs: VMs virtualize the entire hardware stack, including CPU, memory, storage, and 
network interfaces, leading to higher resource usage. 
 Use Cases: 
o Zones: Ideal for scenarios requiring lightweight, isolated environments on the same OS, 
such as development environments, application hosting, or testing. 
o VMs: Suitable for running different operating systems or when complete isolation is 
required, including hardware-level isolation. 
Purpose and Benefits of Using Zones 
 Security: Zones provide a secure environment by isolating applications or services from each 
other. Even if one zone is compromised, the others remain unaffected. 
 Resource Efficiency: Since all zones share the same kernel, they use resources more efficiently 
than VMs. This makes zones ideal for environments where multiple applications need to run 
independently on the same hardware. 
 Ease of Management: Zones allow administrators to manage multiple isolated environments 
with a single operating system instance, simplifying updates, patches, and overall system 
management. 
 Flexibility: Each zone can have different configurations, software versions, and access controls, 
catering to diverse application requirements without needing separate physical machines or full 
VMs. 
Network Configuration in Zones 
 Independent Networking: Each zone can have its own IP address, hostname, and network 
configuration, making it appear as an independent machine on the network. 
 Isolation: Network isolation ensures that traffic in one zone doesn't interfere with other zones, 
enhancing security and performance. 
 Use Cases: This is particularly useful in multi-tenant environments, where different clients or 
services need to be isolated from one another while sharing the same physical infrastructure. 
Handling Kernel Panics in Zones 
 Impact of Kernel Panics: 
o If a kernel panic occurs in the shared kernel, it affects the entire system, including all 
running zones. This is a significant limitation of zones compared to VMs, where a crash 
in one VM doesn’t impact others. 
 System Reboot: In the event of a kernel panic, the entire system, including the global zone and 
all non-global zones, will need to reboot. This downtime affects all services running in all zones, 
highlighting the importance of stability and testing in zoned environments. 
Operating System Updates in Zoned Environments 
 Shared OS Updates: 
o Since all zones share the same underlying operating system, any update to the OS applies 
to all zones. This ensures consistency across zones but also means that careful testing is 
required before applying updates to avoid widespread issues. 
 Simplified Management: 
o The shared nature of the OS simplifies system administration, as updates, patches, and 
security fixes only need to be applied once to affect all zones. However, this also means 
that any issues arising from an update will impact all zones simultaneously. 
Use Cases and Applications of Zones 
 Development and Testing: 
o Zones are often used to create isolated development and testing environments. Developers 
can test new software or configurations in a zone without risking the stability of the 
production environment. 
 Application Hosting: 
o Service providers can use zones to host multiple customer applications on the same 
physical server, each in its own isolated environment, ensuring that one customer’s 
activities do not impact others. 
 Multi-Tenancy: 
o Zones are ideal for multi-tenant applications, where different users or organizations 
require isolated environments on shared hardware. Each tenant gets its own zone, 
ensuring security and resource separation. 
Rebooting and Managing Zones 
 Independent Reboots: 
o Zones can be rebooted independently without affecting other zones. This is useful for 
maintenance, updates, or troubleshooting within a specific zone. 
 Global Zone Control: 
o The global zone, which has complete control over the system, manages all other zones. 
Administrators can control, configure, and monitor zones from the global zone, making it 
the central management point for the system. 
Understanding the Global Zone 
 Role of the Global Zone: 
o The global zone is the primary environment with access to all system resources, including 
hardware, and has full administrative control. It manages all non-global zones and has the 
authority to create, destroy, or modify zones. 
 System-Wide Impact: 
o Actions taken in the global zone, such as system updates or hardware changes, affect all 
non-global zones. As a result, the global zone must be managed with care to avoid 
unintended consequences across all zones. 
Storage Management in Zones 
 Dedicated Storage: 
o Each zone can be allocated its own dedicated storage, ensuring that files and data are 
isolated between zones. This is crucial for maintaining privacy and data integrity in multi- 
tenant environments. 
 Shared Storage in Clustered Environments: 
o In clustered environments, zone files can be stored on shared storage to enable failover 
and high availability. This allows zones to be moved between different physical machines 
in the cluster, enhancing resilience and uptime. 
 File System Layout: 
o Zones often have their root file systems placed in subdirectories under the global zone. 
While this allows for efficient storage management, it also means that disk space usage 
must be carefully monitored to avoid conflicts or shortages. 
Conclusion 
Zoning in operating systems provides a powerful and efficient way to isolate applications and services 
within a single physical machine. By sharing the same kernel but operating independently, zones offer a 
middle ground between the flexibility of VMs and the performance of traditional OS installations. 
Understanding the nuances of zoning, from security and resource management to network configuration 
and storage, is crucial for effectively deploying and managing these environments in real-world 
scenarios.
